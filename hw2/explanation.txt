The flow program is designed to create flexible command workflows by combining simple Unix commands. 
At its core, the program uses three main structures: Node, PipeNode, and Concatenate. 
A Node represents a single command, storing its name and the shell command to be executed. 
When running a node, the program uses fork() to create a child process and execlp() to execute the command, 
allowing any shell command to be run as a separate entity.
PipeNodes connect two nodes, mimicking Unix pipes. To implement this, 
the program creates two child processes: one for the 'from' command that writes its output to a pipe, and another for the 'to' command that reads from this pipe
 as its input.
This setup allows for chaining commands, with the output of one feeding into the input of another.
The Concatenate structure enables sequential execution of multiple nodes or pipes. 
It builds a single shell command by joining all parts with semicolons, then executes this combined command as if it were a single node.

The program's workflow begins by parsing a flow file, which defines the nodes, pipes, and concatenations. 
It stores these in separate arrays for easy access and management. 
The main function takes two arguments: the flow file and an action to execute (which can be a node, pipe, or concatenation name). 
It then identifies the requested action and executes it using the appropriate method. 
This design allows for great flexibility in creating complex command workflows. 
One of the main challenges in implementing this system was handling the different types of actions and ensuring proper process management. 
The program uses careful error handling and proper closing of file descriptors to maintain reliability, especially in complex flows.
 Another challenge was designing a parsing system that could accurately interpret the flow file and create the corresponding structures. 
 The solution involved a systematic approach to reading the file line by line and populating the appropriate data structures. 
 Overall, this implementation provides a powerful tool for users to create intricate command pipelines using simple, building-block-like components, all defined
 in an easy-to-read flow file format.

TEST-1: Tests basic pipe functionality, combining 'ls' and 'wc' commands to count files in a directory.
TEST-2: Verifies concatenation of commands, outputting original content and a modified version where 'o' is replaced with 'u'.
TEST-3: Checks a more complex scenario with nested operations, piping the result of a concatenation to 'wc'.
TEST-4: Examines number operations including generation (seq), sorting, summing, and multiplication, 
        testing the ability to handle multiple operations in sequence.
TEST-5: Focuses on word operations such as generation, sorting, counting occurrences, and uppercase conversion, testing text processing capabilities.
TEST-6: Checks a specific pipe operation for reverse-sorting numbers, verifying correct implementation of sorting in descending order.
TEST-7: Tests error handling by attempting to create a directory and piping the result to 'wc', 
         likely checking how the program handles command outputs and potential errors.

These test cases cover a range of functionalities from basic command execution and piping to more complex data processing and error handling. 
They help ensure that the flow program correctly implements various Unix-like operations and can handle different types of inputs and command combinations.